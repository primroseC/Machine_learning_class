{"cells":[{"cell_type":"markdown","source":["# Exercises - Week 3 - Dataset - Blackjack"],"metadata":{}},{"cell_type":"markdown","source":["## References\n- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n- https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"],"metadata":{}},{"cell_type":"markdown","source":["## Contents\n1. Data Lab notebooks\n2. Two essential transfomers \n1. Dataset intro"],"metadata":{}},{"cell_type":"markdown","source":["## 1. Data Lab notebooks\n1. [Python/Libraries/sklearn/Introduction](https://bentley.cloud.databricks.com/#notebook/210807) \n2. [Python/Libraries/sklearn/Preprocessing](https://bentley.cloud.databricks.com/#notebook/404771)"],"metadata":{}},{"cell_type":"markdown","source":["## 2. Two essential transfomers"],"metadata":{}},{"cell_type":"markdown","source":["This section introduces to essential transformers that create numeric features from categorical features and from text features."],"metadata":{}},{"cell_type":"markdown","source":["There are two types of estimators:\n- A _regressor_ fits a target which is continuous and so numeric. (for instance, linear regression)\n- A _classifier_ fits a binary or categorical target. (for instance,  logistic regression)\n\nThe type of the target variable often determines the type of the estimator (regressor or classifier). \n\nMost estimators require numeric features.\nThe remainder of this section introduces transformers which \n- create numeric features from categorical features \n- create numeric features from text features"],"metadata":{}},{"cell_type":"markdown","source":["A single __categorical feature__ with, for instance, three (3) categories/labels would create three (3) binary features. \n\nThe `OneHotEncoder` class from Scikit-learn is designed to transform categorical features into binary features. See:\n- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n\nSee also the article  [What is One Hot Encoding? Why And When do you have to use it?](https://hackernoon.com/what-is-one-hot-encoding-why-an\nd-when-do-you-have-to-use-it-e3c6186d008f) by Rakshith Vasudev of [HackerNoon](https://hackernoon.com/) at [Medium](https://medium.com/).\n\nThe image below is from the article linked above."],"metadata":{}},{"cell_type":"markdown","source":["![](https://cdn-images-1.medium.com/max/2000/1*Ac4z1rWWuU0TzxJRUM62WA.jpeg)"],"metadata":{}},{"cell_type":"markdown","source":["The __vocabulary__ of a __text feature__  is, in our situation, the set of words occuring in (any value of) that feature.\n(A set has no duplicates.)\n\nA single text feature with a vocabulary of, for instance, 10,000 words would create 10,000 numeric features.\nEach feature corresponds, usually, to a single word. \n\nThere are three basic options for the values of these 10,000 new features:\n1. __binary__: the value `1` indicates that the word (corresponding to the column) occurs in the document (corresponding to the row)\n1. __frequency__: each value indicates the number of occurences of the word (corresponding to the column) in the document (corresponding to the row)\n1. __tf-idf__: each value is the number of occurences of the word (corresponding to the column) in the document (corresponding to the row) divided by the number of documents containing the word (corresponding to the column)\n\nThe `CountVectorizer` and `TfidfVectorizer` classes implement these three options. See:\n- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n\nSee the documentation for an example of each class."],"metadata":{}},{"cell_type":"markdown","source":["__Exercise:__ Copy, paste and run the `CountVectorizer` example."],"metadata":{}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n>>> corpus = [\n...     'This is the first document.',\n...     'This document is the second document.',\n...     'And this is the third one.',\n...     'Is this the first document?',\n... ]\n>>> cvector = CountVectorizer()\n>>> X = cvector.fit_transform(corpus)\n>>> print(cvector.get_feature_names())\n['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n>>> print(X.toarray())  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&apos;and&apos;, &apos;document&apos;, &apos;first&apos;, &apos;is&apos;, &apos;one&apos;, &apos;second&apos;, &apos;the&apos;, &apos;third&apos;, &apos;this&apos;]\n[[0 1 1 1 0 0 1 0 1]\n [0 2 0 1 0 1 1 0 1]\n [1 0 0 1 1 0 1 1 1]\n [0 1 1 1 0 0 1 0 1]]\n</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["__Exercise:__ Copy, paste and run the `TfidfVectorizer` example."],"metadata":{}},{"cell_type":"code","source":[">>> from sklearn.feature_extraction.text import TfidfVectorizer\n>>> corpus = [\n...     'This is the first document.',\n...     'This document is the second document.',\n...     'And this is the third one.',\n...     'Is this the first document?',\n... ]\n>>> vectorizer = TfidfVectorizer()\n>>> X = vectorizer.fit_transform(corpus)\n>>> print(vectorizer.get_feature_names())\n['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n>>> print(X.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&apos;and&apos;, &apos;document&apos;, &apos;first&apos;, &apos;is&apos;, &apos;one&apos;, &apos;second&apos;, &apos;the&apos;, &apos;third&apos;, &apos;this&apos;]\n(4, 9)\n</div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["## 3. Dataset intro"],"metadata":{}},{"cell_type":"markdown","source":["The three datafiles to be used for the project are in an S3 bucket mounted on the directory `/dbfs/mnt/group-ma707`."],"metadata":{}},{"cell_type":"code","source":["%sh ls -hot /dbfs/mnt/group-ma707/data/*"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">-rw-r--r-- 1 root 259K Jan 29 17:44 /dbfs/mnt/group-ma707/data/5tc_plus_ind_vars.csv\n-rw-r--r-- 1 root  12M Jan 29 17:44 /dbfs/mnt/group-ma707/data/mining_com_coal.csv\n-rw-r--r-- 1 root  11M Jan 29 17:44 /dbfs/mnt/group-ma707/data/mining_com_iron_ore.csv\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["The report will investigate at least two datasets. For each we need to do the following:\n1. find or create a target variable (there are at least two)\n1. find or create features to use in predicting the target variable(s)\n\nTo start, display the first few lines of the datafiles to see what we have to work with."],"metadata":{}},{"cell_type":"markdown","source":["The first three lines of the `5tc_plus_ind_vars.csv` file:"],"metadata":{}},{"cell_type":"code","source":["%sh head -n 3 /dbfs/mnt/group-ma707/data/5tc_plus_ind_vars.csv"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&quot;Date&quot;,&quot;BCI&quot;,&quot;C5&quot;,&quot;C7&quot;,&quot;P1A_03&quot;,&quot;P2A_03&quot;,&quot;P4_03&quot;,&quot;P3A~IV&quot;,&quot;SHFE_AL3&quot;,&quot;RICI&quot;,&quot;ICE_KC3&quot;,&quot;CME_SM3&quot;,&quot;CME_LC2&quot;,&quot;OPEC_ORB&quot;,&quot;SHFE_CU3&quot;,&quot;CME_LN1&quot;,&quot;CME_FC3&quot;,&quot;P3A_03&quot;,&quot;SHFE_RB3&quot;,&quot;CME_S2&quot;,&quot;ICE_SB3&quot;,&quot;CME_LN3&quot;,&quot;CME_LN2&quot;,&quot;ICE_TIB3&quot;,&quot;ICE_TIB4&quot;,&quot;BCI_5TC&quot;\n2011-12-05,3390,12.529,15.718,15329,24935,3324,16.54,16.54,3688.22,3688.22,3688.22,3688.22,110.3,110.3,110.3,110.3,10503,10503,1136.5,1136.5,1136.5,1136.5,-6.66,-6.6,29966\n2011-12-06,3387,12.379,15.705,15328,24967,3288,16.55,16.55,3700.6,3700.6,3700.6,3700.6,109.49,109.49,109.49,109.49,10412,10412,1139.5,1139.5,1139.5,1139.5,-6.84,-6.77,29990\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["The last column (`BCI_5TC`) is one of our target variables. \n\nNotice the `Date` field. The dataframe produced with the above target variable will be a time series (each record has data from a specific date). The target variable will be predicted with data from previous dates/times. We will write transformer classes to create features that are lagged values of these columns.\n\nThe target variable will be predicted from these lagged values. Features from the other files can also be used."],"metadata":{}},{"cell_type":"markdown","source":["__Exercise:__ \n- Read in this file using the pandas `read_csv` function. \n- Store the resulting dataframe in `bci_5tc_plus_pdf`."],"metadata":{}},{"cell_type":"markdown","source":["Here we import the pandas library into python and read in the specified csv file.  There are no other steps needed here because the csv file does not contain data that requires special coding"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nbci_5tc_plus_pdf = pd.read_csv('/dbfs/mnt/group-ma707/data/5tc_plus_ind_vars.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["The first nine lines of the `mining_com_coal.csv` file:"],"metadata":{}},{"cell_type":"code","source":["%sh head -n 9 /dbfs/mnt/group-ma707/data/mining_com_coal.csv"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">content,date,origin,subtitle,tags,title,url\n&quot;Electric cars are better for the environment than traditional gasoline models, and that benefit will grow as power generators shift away from coal.\nThat’s the conclusion of research by BloombergNEF, which found carbon dioxide emissions from battery-powered vehicles were about 40 percent lower than for internal combustion engines last year. The difference was biggest in Britain and the U.K., which have large renewables industries. It still held in China, which is more reliant on coal to make electricity. Carbon dioxide emissions from battery-powered vehicles were about 40 percent lower than for internal combustion engines last yearThe report adds clarity to the debate about the lifetime emissions of electric vehicles, which while they don’t pollute on the road do consume electricity that is often generated using fossil fuels. BNEF’s research assumes that electric cars will become cleaner in the coming years as utilities close coal plants and draw more energy from wind and solar farms, a process well underway almost everywhere except Southeast Asia.\n“When an internal combustion vehicle rolls off the line its emissions per km are set, but for an EV they keep falling every year as the grid gets cleaner,” Colin McKerracher, a transport analyst at BNEF said.\nThe chart above shows BNEF’s forecasts for how much the gap will grow, with China expected to make rapid progress as its renewables industry takes a bigger share of the power generation market in the coming years.\nThe widespread adoption of renewables will decrease average emissions by as much as 90 percent in the U.K. and over a third in Japan out to 2040, according to BNEF.\nThe global share of zero-carbon electricity generation is set to increase from 38 percent last year to 63 percent by 2040, according to projections from BNEF. While technological improvements will see related emissions from combustion engines falling by about 1.9 percent a year through to 2040, pollution from electric vehicles will fall anywhere from 3 percent and 10 percent annually. That’s largely because of grid decarbonization but also reduced electricity consumption, BNEF says.\n(By Jeremy Hodges)&quot;,2019-01-15T23:04:53+00:00,bloomberg-news,,britain china coal cobalt copper europe graphite lithium nickel u-s-a,Electric cars seen getting cleaner even where grids rely on coal,http://www.mining.com/web/electric-cars-seen-getting-cleaner-even-grids-rely-coal/\n&quot;Project Halo, the South African consortium selected as the preferred bidder in the highly contested acquisition of coal mines previously owned by the Gupta family, is denying circulating allegations of favouritism for allegedly being linked to the same family.\n</div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["All columns from this file can be used to produce features for the `BCI_5TC` target variable."],"metadata":{}},{"cell_type":"markdown","source":["__Exercise:__ \n- Read in this file using the pandas `read_csv` function.\n- You will encounter an error. Search to find the single parameter to avoid the error. \n- Store the resulting dataframe in `mining_com_coal_pdf`."],"metadata":{}},{"cell_type":"markdown","source":["The next two lines of code take the csv files and encode them usng the \"ISO...\" method relatiive to the dataset.  This method allows all the data to be read into the dataframe correctly,  but will require some modifications later on for use in the subsequent exercises."],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nmining_com_coal_pdf=pd.read_csv('/dbfs/mnt/group-ma707/data/mining_com_coal.csv', encoding = \"ISO-8859-1\")\nmining_com_coal_pdf.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">17</span><span class=\"ansired\">]: </span>\n                                             content  ...                                                url\n0  Electric cars are better for the environment t...  ...  http://www.mining.com/web/electric-cars-seen-g...\n1  Project Halo, the South African consortium sel...  ...  http://www.mining.com/project-halo-rejects-fav...\n2  * China&apos;s 2018 iron ore imports fall to 1.064 ...  ...  http://www.mining.com/web/chinas-2018-iron-ore...\n3  Angela Merkel this week will seek to bridge di...  ...  http://www.mining.com/web/merkel-seeks-heal-ri...\n4  A coal mine roof collapse in northwest China&apos;s...  ...  http://www.mining.com/web/coal-mine-collapse-c...\n\n[5 rows x 7 columns]\n</div>"]}}],"execution_count":30},{"cell_type":"markdown","source":["__Exercise:__ \n- Read in the other file (not displayed above, but in the same directory) using the pandas `read_csv` function.\n- You will encounter an error. Try the fix you found above. \n- Store the resulting dataframe in `mining_com_iron_ore_pdf`."],"metadata":{}},{"cell_type":"markdown","source":["See comments above - the same problem is found and the same solution is used."],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nmining_com_iron_ore_pdf = pd.read_csv ('/dbfs/mnt/group-ma707/data/mining_com_iron_ore.csv', encoding = \"ISO-8859-1\")\nmining_com_iron_ore_pdf[['origin','subtitle']]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">5</span><span class=\"ansired\">]: </span>\n                                             origin  subtitle\n0                                    bloomberg-news       NaN\n1                                           reuters       NaN\n2                                           reuters       NaN\n3                                           reuters       NaN\n4                                 mining.com-editor       NaN\n5                                 bloomberg-opinion       NaN\n6                                           reuters       NaN\n7                                           reuters       NaN\n8                                  cecilia-jamasmie       NaN\n9                                           reuters       NaN\n10                                   bloomberg-news       NaN\n11                                          reuters       NaN\n12                                          reuters       NaN\n13                                 cecilia-jamasmie       NaN\n14                                   bloomberg-news       NaN\n15                                   bloomberg-news       NaN\n16                                          reuters       NaN\n17                                          reuters       NaN\n18                                          reuters       NaN\n19                                         frik-els       NaN\n20                                          reuters       NaN\n21                                          reuters       NaN\n22                                         frik-els       NaN\n23                                          reuters       NaN\n24                                 cecilia-jamasmie       NaN\n25                             northern-miner-staff       NaN\n26                             northern-miner-staff       NaN\n27                                   bloomberg-news       NaN\n28                                          reuters       NaN\n29                                 cecilia-jamasmie       NaN\n...                                             ...       ...\n3997                              mining.com-editor       NaN\n3998                               engineering-news       NaN\n3999  infomine---mining-equipment-and-supplier-news       NaN\n4000  infomine---mining-equipment-and-supplier-news       NaN\n4001  infomine---mining-equipment-and-supplier-news       NaN\n4002  infomine---mining-equipment-and-supplier-news       NaN\n4003  infomine---mining-equipment-and-supplier-news       NaN\n4004                                    mining-news       NaN\n4005                                     dan-oancea       NaN\n4006                                    mining-news       NaN\n4007                                    mining-news       NaN\n4008  infomine---mining-equipment-and-supplier-news       NaN\n4009                                    mining-news       NaN\n4010  infomine---mining-equipment-and-supplier-news       NaN\n4011                                    mining-news       NaN\n4012                           international-mining       NaN\n4013  infomine---mining-equipment-and-supplier-news       NaN\n4014                                    mining-news       NaN\n4015                              mining.com-editor       NaN\n4016  infomine---mining-equipment-and-supplier-news       NaN\n4017  infomine---mining-equipment-and-supplier-news       NaN\n4018  infomine---mining-equipment-and-supplier-news       NaN\n4019  infomine---mining-equipment-and-supplier-news       NaN\n4020  infomine---mining-equipment-and-supplier-news       NaN\n4021  infomine---mining-equipment-and-supplier-news       NaN\n4022  infomine---mining-equipment-and-supplier-news       NaN\n4023  infomine---mining-equipment-and-supplier-news       NaN\n4024  infomine---mining-equipment-and-supplier-news       NaN\n4025  infomine---mining-equipment-and-supplier-news       NaN\n4026  infomine---mining-equipment-and-supplier-news       NaN\n\n[4027 rows x 2 columns]\n</div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["__Exercise:__ \n- Reset the column names of each dataframe to use lower case and snake case. \n- Display the column attribute of each dataframe."],"metadata":{}},{"cell_type":"markdown","source":["The following commands change the column names to be lower case (denoted in the coding by 'lower') ad to use snake case by replacing all spaces between words with underscores. This allows the code output to be easily read and interpreted by another programmer."],"metadata":{}},{"cell_type":"code","source":["mining_com_iron_ore_pdf.columns =  mining_com_iron_ore_pdf.columns.str.lower().str.replace(' ','_')\nmining_com_coal_pdf.columns = mining_com_coal_pdf.columns.str.lower().str.replace(' ','_')\nbci_5tc_plus_pdf.columns = bci_5tc_plus_pdf.columns.str.lower().str.replace(' ','_')\nbci_5tc_plus_pdf.info()\nbci_5tc_plus_pdf.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;\nRangeIndex: 1602 entries, 0 to 1601\nData columns (total 26 columns):\ndate        1602 non-null object\nbci         1602 non-null int64\nc5          1602 non-null float64\nc7          1602 non-null float64\np1a_03      1602 non-null int64\np2a_03      1602 non-null int64\np4_03       1602 non-null int64\np3a~iv      1602 non-null float64\nshfe_al3    1602 non-null float64\nrici        1602 non-null float64\nice_kc3     1602 non-null float64\ncme_sm3     1602 non-null float64\ncme_lc2     1602 non-null float64\nopec_orb    1602 non-null float64\nshfe_cu3    1602 non-null float64\ncme_ln1     1602 non-null float64\ncme_fc3     1602 non-null float64\np3a_03      1602 non-null int64\nshfe_rb3    1602 non-null int64\ncme_s2      1602 non-null float64\nice_sb3     1602 non-null float64\ncme_ln3     1602 non-null float64\ncme_ln2     1602 non-null float64\nice_tib3    1602 non-null float64\nice_tib4    1602 non-null float64\nbci_5tc     1602 non-null int64\ndtypes: float64(18), int64(7), object(1)\nmemory usage: 325.5+ KB\n<span class=\"ansired\">Out[</span><span class=\"ansired\">39</span><span class=\"ansired\">]: </span>\n         date   bci      c5      c7  ...  cme_ln2  ice_tib3  ice_tib4  bci_5tc\n0  2011-12-05  3390  12.529  15.718  ...  1136.50     -6.66     -6.60    29966\n1  2011-12-06  3387  12.379  15.705  ...  1139.50     -6.84     -6.77    29990\n2  2011-12-07  3405  12.163  15.923  ...  1141.00     -6.37     -6.27    30337\n3  2011-12-08  3529  12.421  16.286  ...  1142.25     -7.10     -7.00    31803\n4  2011-12-09  3697  13.325  16.486  ...  1116.50     -7.43     -7.37    33276\n\n[5 rows x 26 columns]\n</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["__Exercise:__ Check each dataframe to ensure that it looks reasonable, using the `info`, `head` and `tail` methods."],"metadata":{}},{"cell_type":"markdown","source":["We did not soend much time here, as we reached the conclusion that the dataframes looked reasonable after a couple of iterations through the workbook.  We noted the usefulness of the info method particularly, and discussed how this might be used later on when determining our prooject dataset."],"metadata":{}},{"cell_type":"code","source":["mining_com_iron_ore_pdf.head()\nmining_com_iron_ore_pdf.tail()\nmining_com_coal_pdf.head()\nbci_5tc_plus_pdf.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">20</span><span class=\"ansired\">]: </span>\n         date   bci      c5      c7  ...  cme_ln2  ice_tib3  ice_tib4  bci_5tc\n0  2011-12-05  3390  12.529  15.718  ...  1136.50     -6.66     -6.60    29966\n1  2011-12-06  3387  12.379  15.705  ...  1139.50     -6.84     -6.77    29990\n2  2011-12-07  3405  12.163  15.923  ...  1141.00     -6.37     -6.27    30337\n3  2011-12-08  3529  12.421  16.286  ...  1142.25     -7.10     -7.00    31803\n4  2011-12-09  3697  13.325  16.486  ...  1116.50     -7.43     -7.37    33276\n\n[5 rows x 26 columns]\n</div>"]}}],"execution_count":39},{"cell_type":"markdown","source":["__Exercise:__ Notice that each file/dataframe has a date variable. \n- Use these variables to join these dataframes (created from these files) into a single dataframe. \n- Use a left join with `bci_5tc_plus_pdf` as your base dataframe. \n- Store your result in `bci_5tc_plus_mining_com_pdf`."],"metadata":{}},{"cell_type":"markdown","source":["The following code takes the dataframes specified above, and performs a left merge on them.  Because the iron ore dataframe and the coal dataframe dates were substantially longer (due to timestamps) than the bci dataframe, the dates were sliced to represnt values from 0-10, elimiinating the time portion of the date and allowing all dates to match correctly."],"metadata":{}},{"cell_type":"code","source":["mining_com_iron_ore_pdf['date']=mining_com_iron_ore_pdf['date'].str.slice(0,10)\nmining_com_coal_pdf['date']=mining_com_coal_pdf['date'].str.slice(0,10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":42},{"cell_type":"code","source":["bci_5tc_plus_mining_com_pdf1=pd.merge(bci_5tc_plus_pdf,mining_com_iron_ore_pdf,how='left',on=['date', 'date'])\nbci_5tc_plus_mining_com_pdf=pd.merge(bci_5tc_plus_mining_com_pdf1,mining_com_coal_pdf,how='left',on=['date', 'date'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"markdown","source":["__Exercise:__ Check the result of your join to see if there were any rows in the base file that did not match with a row in either of the two _mining_ dataframes."],"metadata":{}},{"cell_type":"markdown","source":["bci_5tc_plus_pdf has 1602 entries and bci_5tc_plus_mining_com_pdf has 6665 entries. It means that some rows in the base file matches mutiple rows in other two mining dataframes. There are some missing values in content_x and content_y, which means some rows in the case didn't match with a row in either of the two mining dataframes"],"metadata":{}},{"cell_type":"code","source":["bci_5tc_plus_mining_com_pdf.info()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;\nInt64Index: 6665 entries, 0 to 6664\nData columns (total 38 columns):\ndate          6665 non-null object\nbci           6665 non-null int64\nc5            6665 non-null float64\nc7            6665 non-null float64\np1a_03        6665 non-null int64\np2a_03        6665 non-null int64\np4_03         6665 non-null int64\np3a~iv        6665 non-null float64\nshfe_al3      6665 non-null float64\nrici          6665 non-null float64\nice_kc3       6665 non-null float64\ncme_sm3       6665 non-null float64\ncme_lc2       6665 non-null float64\nopec_orb      6665 non-null float64\nshfe_cu3      6665 non-null float64\ncme_ln1       6665 non-null float64\ncme_fc3       6665 non-null float64\np3a_03        6665 non-null int64\nshfe_rb3      6665 non-null int64\ncme_s2        6665 non-null float64\nice_sb3       6665 non-null float64\ncme_ln3       6665 non-null float64\ncme_ln2       6665 non-null float64\nice_tib3      6665 non-null float64\nice_tib4      6665 non-null float64\nbci_5tc       6665 non-null int64\ncontent_x     6210 non-null object\norigin_x      6225 non-null object\nsubtitle_x    0 non-null float64\ntags_x        6225 non-null object\ntitle_x       6225 non-null object\nurl_x         6225 non-null object\ncontent_y     6271 non-null object\norigin_y      6275 non-null object\nsubtitle_y    0 non-null float64\ntags_y        6275 non-null object\ntitle_y       6275 non-null object\nurl_y         6276 non-null object\ndtypes: float64(20), int64(7), object(11)\nmemory usage: 2.0+ MB\n</div>"]}}],"execution_count":46},{"cell_type":"markdown","source":["From the `bci_5tc_plus_mining_com_pdf` dataframe, will create a dataframe with features to predict the `bci_5tc`. \n\nThe remaining exercises create another dataframe, that will contain a different target."],"metadata":{}},{"cell_type":"markdown","source":["__Exercise:__ \n- Use the `CountVectorizer` class to create numeric columns from each of the three text columns in the `mining_com_iron_ore_pdf` dataframe. \n- Display the shape of each of results of the `transform` method for each of these text columns."],"metadata":{}},{"cell_type":"markdown","source":["The following code utilizes the countectorizer methods descrbed above, note the need top transform the values of the content, origin, and tags columns away from ISO to Unicode (specified by U). After this, the shape of all the columns are shown, we note that the shapes all differ, because the tags and origin values have less unique information than the overall content"],"metadata":{}},{"cell_type":"code","source":["mining_content = cvector.fit_transform(mining_com_iron_ore_pdf['content'].values.astype('U'))\nmining_origin = cvector.fit_transform(mining_com_iron_ore_pdf['origin'].values.astype('U'))\nmining_tags = cvector.fit_transform (mining_com_iron_ore_pdf['tags'].values.astype('U'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":50},{"cell_type":"code","source":["mining_content.shape,mining_origin.shape,mining_tags.shape"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">58</span><span class=\"ansired\">]: </span>((4027, 39727), (4027, 455), (4027, 728))\n</div>"]}}],"execution_count":51},{"cell_type":"markdown","source":["__Exercise:__ produce a count of the unique values of each of the `origin` columns from each of the _mining_ dataframes.\n(produce two results)"],"metadata":{}},{"cell_type":"markdown","source":["The following code looks to utilize the count vectorize method defined above, and then utilizes the get feture names associated with the function.  By using. the length of the get features name we can see the number of unique values in the two dataframes."],"metadata":{}},{"cell_type":"code","source":["print(len(set(mining_com_coal_pdf['origin'].values)))\nprint(len(set(mining_com_iron_ore_pdf['origin'].values)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">349\n257\n</div>"]}}],"execution_count":54},{"cell_type":"markdown","source":["__Exercise:__ from one of the _mining_ dataframes:\n- transform the `origin` column using the `OneHotEncoder` class \n- display the shape of the result"],"metadata":{}},{"cell_type":"code","source":[">>> from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n>>> enc = OneHotEncoder(handle_unknown='ignore')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":56},{"cell_type":"markdown","source":["In order to use the one hot encoder method we needed to determine numeric values for the different origins.  In order to do thiis we decided to utiliize the pandas function 'get dummies' which created dumy variables for each origin.  We were then able to use our encoder method, and generate a sparse array as defined, and count the different values using the shape function."],"metadata":{}},{"cell_type":"code","source":["le = LabelEncoder()\nenc= OneHotEncoder()\ntmp=le.fit_transform(mining_com_coal_pdf['origin'].values.tolist())\nx_train = enc.fit_transform(tmp.reshape(-1, 1))\nx_train.shape"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.5/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify &quot;categories=&apos;auto&apos;&quot;.\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n<span class=\"ansired\">Out[</span><span class=\"ansired\">71</span><span class=\"ansired\">]: </span>(4460, 349)\n</div>"]}}],"execution_count":58},{"cell_type":"markdown","source":["We note that within the one hot encoder method shown above we get a result of 349 unique values, indicating that the one hot encoder method provided a similar result to that of the unique count methods we performed earlier."],"metadata":{}},{"cell_type":"markdown","source":["__The End__"],"metadata":{}}],"metadata":{"name":"W03.1 Ex. Dataset","notebookId":999185},"nbformat":4,"nbformat_minor":0}
