{"cells":[{"cell_type":"markdown","source":["#MA707 Metrics & Models\n%md ## References\n- [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)\n%md Text and links below from Scikit-learn reference link above: \n- [metrics.explained_variance_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score): \nExplained variance regression score function\n- [metrics.mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error): \nMean absolute error regression loss\n- [metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error): \nMean squared error regression loss\n- [metrics.mean_squared_log_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error): \nMean squared logarithmic error regression loss\n- [metrics.median_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error): \nMedian absolute error regression loss\n- [metrics.r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score): \nR^2 (coefficient of determination) regression score function.\n%run \"../Report/0.2 Feature creation (inc)\"\n%python\nimport pandas as pd\nbci_pdf = pd.read_csv('/dbfs/mnt/group-ma707/data/5tc_plus_ind_vars.csv') \\\n            .rename(columns={'P3A~IV':'P3A_IV'}) \\\n            .assign(date=lambda pdf: pd.to_datetime(pdf.Date)) \\\n            .drop('Date', axis=1) \\\n            .sort_index(ascending=True)\nbci_pdf.columns = bci_pdf.columns.str.lower()\nbci_pdf.info() # 1602 non-null for all vars same count for index\n%python\nimport numpy as np\nimport pandas as pd\ncoal_pdf = \\\npd.read_csv('/dbfs/mnt/group-ma707/data/mining_com_coal.csv', \n            encoding='ISO-8859-1'\n           ) \\\n  .loc[:,['date','tags','title','content']] \\\n  .fillna({'tags'   :'',\n           'content':'',\n           'title'  :''\n          }) \\\n  .assign(date   =lambda pdf: pd.to_datetime(pd.to_datetime(pdf.date).dt.date)) \\\n  .groupby(by='date') \\\n  .agg({'tags'   : lambda ser: ' '.join(ser),\n        'content': lambda ser: ' '.join(ser),\n        'title'  : lambda ser: ' '.join(ser)}) \\\n  .resample('D') \\\n  .pad() \\\n  .reset_index()\ncoal_pdf.info()\n%python\nimport numpy as np\nimport pandas as pd\nore_pdf = \\\npd.read_csv('/dbfs/mnt/group-ma707/data/mining_com_iron_ore.csv', \n            encoding='ISO-8859-1'\n           ) \\\n  .loc[:,['date','tags','title','content']] \\\n  .fillna({'tags'   :'',\n           'content':'',\n           'title'  :''\n          }) \\\n  .assign(date = lambda pdf: pd.to_datetime(pd.to_datetime(pdf.date,utc=True).dt.normalize().dt.date)) \\\n  .groupby(by='date') \\\n  .agg({'tags'   : lambda ser: ' '.join(ser),\n        'content': lambda ser: ' '.join(ser),\n        'title'  : lambda ser: ' '.join(ser)}) \\\n  .resample('D') \\\n  .pad() \\\n  .reset_index()\nore_pdf.info(10)\n%python\nimport pandas as pd\nbci_coal_pdf = \\\npd.concat(objs=[ bci_pdf.set_index('date'), \n                coal_pdf.set_index('date')], \n          join='inner',\n          axis=1\n         ) \\\n  .reset_index()\nbci_coal_pdf.info()\n%python\nimport pandas as pd\nbci_ironore_pdf = \\\npd.concat(objs=[bci_pdf.set_index('date'), \n                ore_pdf.set_index('date')], \n          join='inner',\n          axis=1\n         ) \\\n  .reset_index()\nbci_ironore_pdf.info()\n%python\nimport pandas as pd\nbci_dual_pdf = \\\npd.concat(objs=[bci_coal_pdf.set_index('date'), \n                ore_pdf.set_index('date')], \n          join='inner',\n          axis=1\n         ) \\\n  .reset_index()\nbci_dual_pdf.info()\n%python\nimport pandas as pd\nbci_dual_pdf = \\\npd.concat(objs=[ bci_pdf.set_index('date'), \n                 ore_pdf.set_index('date'),\n                coal_pdf.set_index('date')], \n          join='inner',\n          axis=1\n         ) \\\n  .reset_index()\nbci_dual_pdf.info()\n\n%python \ndef get_count_vect_all_three_plus_all_ts_pipe():\n  from sklearn.pipeline import FeatureUnion, Pipeline\n  return Pipeline(steps=[\n    ('fea_one', FeatureUnionDF(transformer_list=[\n      ('tgt_var'    ,CreateTargetVarDF(var='bci_5tc')),\n      ('dt_vars'    ,CreateDatetimeVarsDF(var='date')),\n      ('lag_txt_vars',CreateLagVarsDF(var_list=['tags','content','title'],\n                                      lag_list=[3])),\n    ])),\n    ('drop_na_rows'  ,DropNaRowsDF(how='any')),\n    ('fea_two', FeatureUnionDF(transformer_list=[\n      ('named_vars' ,CreateNamedVarsDF(except_list=['tags_lag3','content_lag3','title_lag3'])),\n      ('cnt_tags'   , CountVectColDF(col_name=   'tags_lag3',prefix='cnt_tags_'   ,add_stop_words=[])),\n      ('cnt_content', CountVectColDF(col_name='content_lag3',prefix='cnt_content_',add_stop_words=[])),  \n      ('cnt_title'  , CountVectColDF(col_name=  'title_lag3',prefix='cnt_title_'  ,add_stop_words=[])),  \n    ])),\n    ('drop_na_rows_again'  ,DropNaRowsDF(how='any')),\n  ])\n%md Ask about this error - creating new feature target pipelines is simple once we determine why this isnt working - because its just about changing what we count, and what we look at in terms of lagged variables, tfidf vectorizer, etc.\nget_count_vect_all_three_plus_all_ts_pipe() \\\n  .fit(bci_coal_pdf) \\\n  .transform(bci_coal_pdf)"],"metadata":{}}],"metadata":{"name":"W13.Z Unused (1)","notebookId":1399751},"nbformat":4,"nbformat_minor":0}
