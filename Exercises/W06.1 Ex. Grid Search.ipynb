{"cells":[{"cell_type":"markdown","source":["# Exercises - Week 6 - Grid Search - Blackjack"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["## References\n\n- https://scikit-learn.org/stable/modules/grid_search.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n- https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection\n- https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n- https://scikit-learn.org/stable/modules/model_evaluation.html\n- https://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n- https://scikit-learn.org/stable/tutorial/statistical_inference/index.html"],"metadata":{}},{"cell_type":"markdown","source":["## Contents\n1. Setup \n2. Grid search\n3. Datasets"],"metadata":{}},{"cell_type":"markdown","source":["## 1. Setup"],"metadata":{}},{"cell_type":"markdown","source":["Below libraries are loaded, a helper function is defined, and the features dataframe and target series are created for use by the `GridSearchCV` demonstrations that follow."],"metadata":{}},{"cell_type":"markdown","source":["Load libraries and display version numbers."],"metadata":{}},{"cell_type":"code","source":["import pandas  as pd\nimport numpy   as np\nimport sklearn as sk\nprint('sklearn',sk.__version__)\nprint('pandas ',pd.__version__)\nprint('numpy  ',np.__version__)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">sklearn 0.20.3\npandas  0.24.2\nnumpy   1.16.2\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["These version numbers may not be the most recent or correspond to the documentation you locate via Google."],"metadata":{}},{"cell_type":"markdown","source":["The `display_pdf` function displays a pandas dataframe using the databricks display function."],"metadata":{}},{"cell_type":"code","source":["def display_pdf(a_pdf):\n  display(spark.createDataFrame(a_pdf))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["The demonstrations below all use the Boston housing dataset. The following code cell displays its dimensions."],"metadata":{}},{"cell_type":"code","source":["from sklearn.datasets import load_boston\nload_boston().data.shape"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>(506, 13)\n</div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["The following cell displayes the first three rows of features."],"metadata":{}},{"cell_type":"code","source":["load_boston().data[ :3]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">5</span><span class=\"ansired\">]: </span>\narray([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n        1.5300e+01, 3.9690e+02, 4.9800e+00],\n       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n        1.7800e+01, 3.9690e+02, 9.1400e+00],\n       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n        1.7800e+01, 3.9283e+02, 4.0300e+00]])\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["Notice that all values are numeric (which makes sense as they are stored in a numpy array)."],"metadata":{}},{"cell_type":"markdown","source":["The following cell displayes the first three values of the target."],"metadata":{}},{"cell_type":"code","source":["load_boston().target[:3]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>array([24. , 21.6, 34.7])\n</div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["Count the number of missing values in the dataset. (There aren't any.)"],"metadata":{}},{"cell_type":"code","source":["import numpy  as np\nfrom sklearn.datasets import load_boston\nnp.sum(np.isnan(load_boston().data))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>0\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["It would be helpful to have some missing values in the dataset. The following code cell creates 20 missing values in `bos_fea_array`."],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nfrom sklearn.datasets import load_boston\nfrom random           import randint\nbos_fea_array = load_boston().data \nfor n in range(20): \n  bos_fea_array[randint(0,502), \n                randint(0,12)\n               ] = np.nan"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["The following cell check that we do in fact have 20 missing values."],"metadata":{}},{"cell_type":"code","source":["np.sum(np.isnan(bos_fea_array))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">9</span><span class=\"ansired\">]: </span>20\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["Define two functions to provide the target series and feature dataframe for the Boston housing dataset, including the additional missing values."],"metadata":{}},{"cell_type":"code","source":["def bos_tgt_ser(): \n  import pandas as pd\n  from sklearn import datasets\n  return pd.Series(data=datasets.load_boston().target)\n\ndef bos_fea_pdf(): \n  import pandas as pd\n  from sklearn.datasets import load_boston\n  bos_fea_array   = load_boston().data \n  bos_fea_columns = load_boston().feature_names\n  for n in range(20): \n    bos_fea_array[randint(0,502), \n                  randint(0,12)\n                 ] = np.nan\n  return pd.DataFrame(data   =          bos_fea_array,\n                      columns=pd.Series(bos_fea_columns).str.lower()\n                     )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["The commands below display summary details about the target and features, in the next two cells."],"metadata":{}},{"cell_type":"code","source":["bos_fea_pdf().info()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;\nRangeIndex: 506 entries, 0 to 505\nData columns (total 13 columns):\ncrim       505 non-null float64\nzn         503 non-null float64\nindus      506 non-null float64\nchas       502 non-null float64\nnox        505 non-null float64\nrm         505 non-null float64\nage        505 non-null float64\ndis        504 non-null float64\nrad        504 non-null float64\ntax        505 non-null float64\nptratio    505 non-null float64\nb          506 non-null float64\nlstat      503 non-null float64\ndtypes: float64(13)\nmemory usage: 51.5 KB\n</div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["The features dataframe only contains `float` values/columns."],"metadata":{}},{"cell_type":"code","source":["bos_tgt_ser()[:3]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>\n0    24.0\n1    21.6\n2    34.7\ndtype: float64\n</div>"]}}],"execution_count":30},{"cell_type":"markdown","source":["The target series is also of type `float`."],"metadata":{}},{"cell_type":"markdown","source":["## 2. Grid search"],"metadata":{}},{"cell_type":"markdown","source":["Grid search is a technique for creating models using a range of hyper-parameters and then scoring these predictions made by these models.\n\nFirst, create a pipeline below which:\n1. Imputes missing values\n2. Scales values to the `0` to `1` range\n3. Performs a linear regression on the data"],"metadata":{}},{"cell_type":"code","source":["from sklearn.pipeline        import Pipeline\nfrom sklearn.linear_model    import LogisticRegression, LinearRegression\nfrom sklearn.preprocessing   import MinMaxScaler\nfrom sklearn.impute          import SimpleImputer\n\nest_pipe = Pipeline([\n  ('imp', SimpleImputer()),\n  ('sca', MinMaxScaler()),\n  ('lrg', LinearRegression())\n])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"markdown","source":["This pipeline will be used in the grid search example below."],"metadata":{}},{"cell_type":"markdown","source":["Consider the `parameters` dictionary below:\n- The first three characters of the keys correspond to names of pipeline steps\n- Two underscores follow the name of the pipeline step\n- The remainder of the key is the name of an init parameter of the named step\n- The value (of the key) is a list of possible values for that named init parameter"],"metadata":{}},{"cell_type":"code","source":["parameters = {\n  'imp__strategy': ['mean', 'median'],\n  'lrg__fit_intercept': [True, False]\n}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":37},{"cell_type":"markdown","source":["The following cell performs a grid search. This means that the above pipeline is run:\n- for all combinations of parameters listed in the `parameters` dictionary\n- in this case, each model created with a combination of hyper-parameters, is fit on the train dataset and predicts on the test dataset of each of three cross validation pairs (see the `cv` parameter)\n\nThe keys of the `parameters` dictionary are hyper-parameters of the transformers or final estimator of the pipeline.\n\nThe code below:\n1. Creates a `GridSearchCV` object, which is an estimator\n2. Fits this object to the features and target of the Boston housing dataset\n\nNotice three key parameters of this object:\n1. `estimator`: the pipeline, which is a series of transformer objects and a final estimator\n2. `param_grid`: the parameters (hyper-parameters of the step objects)\n3. `cv`: the number of cross validation pairs"],"metadata":{}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n\nest_grid_obj = GridSearchCV(estimator=est_pipe, \n                            param_grid=parameters,\n                            cv=3, \n                            iid=False,\n                            return_train_score=True\n                           )\nest_grid_obj.fit(bos_fea_pdf(), \n                 bos_tgt_ser()\n                )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">15</span><span class=\"ansired\">]: </span>\nGridSearchCV(cv=3, error_score=&apos;raise-deprecating&apos;,\n       estimator=Pipeline(memory=None,\n     steps=[(&apos;imp&apos;, SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy=&apos;mean&apos;,\n       verbose=0)), (&apos;sca&apos;, MinMaxScaler(copy=True, feature_range=(0, 1))), (&apos;lrg&apos;, LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False))]),\n       fit_params=None, iid=False, n_jobs=None,\n       param_grid={&apos;lrg__fit_intercept&apos;: [True, False], &apos;imp__strategy&apos;: [&apos;mean&apos;, &apos;median&apos;]},\n       pre_dispatch=&apos;2*n_jobs&apos;, refit=True, return_train_score=True,\n       scoring=None, verbose=0)\n</div>"]}}],"execution_count":39},{"cell_type":"markdown","source":["The output indicates the steps of the pipeline, including the default parameters for each."],"metadata":{}},{"cell_type":"markdown","source":["Grid search (`GridSearchCV` in Python) is often used to optimize the choice of hyper-parameters in order that the pipeline (as determined by its hyper-parameters) produces the best prediction score. \n\nWe use `GridSearchCV`  to investigate the effects of the chosen hyper-parameter values on the scoring of the predictions made by the estimator pipeline. This will allow us to better understand a range of estimators and transformers, through the effect of their hyper-parameters on the scoring of their predictions."],"metadata":{}},{"cell_type":"markdown","source":["In particular, the `GridSearchCV` object contains the `cv_results_` attribute, which contains information on the hyper-parameters and the scoring."],"metadata":{}},{"cell_type":"code","source":["est_grid_obj.best_params_"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">16</span><span class=\"ansired\">]: </span>{&apos;lrg__fit_intercept&apos;: True, &apos;imp__strategy&apos;: &apos;mean&apos;}\n</div>"]}}],"execution_count":43},{"cell_type":"code","source":["est_grid_obj.cv_results_"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">17</span><span class=\"ansired\">]: </span>\n{&apos;split0_train_score&apos;: array([0.74986759, 0.65912256, 0.75035736, 0.66075196]),\n &apos;std_train_score&apos;: array([0.08843996, 0.13322108, 0.08882926, 0.13365675]),\n &apos;params&apos;: [{&apos;lrg__fit_intercept&apos;: True, &apos;imp__strategy&apos;: &apos;mean&apos;},\n  {&apos;lrg__fit_intercept&apos;: False, &apos;imp__strategy&apos;: &apos;mean&apos;},\n  {&apos;lrg__fit_intercept&apos;: True, &apos;imp__strategy&apos;: &apos;median&apos;},\n  {&apos;lrg__fit_intercept&apos;: False, &apos;imp__strategy&apos;: &apos;median&apos;}],\n &apos;split1_test_score&apos;: array([0.53624436, 0.43885148, 0.53845367, 0.44344075]),\n &apos;std_test_score&apos;: array([2.96999718, 6.08046866, 3.0307479 , 6.15657066]),\n &apos;rank_test_score&apos;: array([1, 3, 2, 4], dtype=int32),\n &apos;mean_train_score&apos;: array([0.76281096, 0.67856238, 0.76276306, 0.67896084]),\n &apos;param_imp__strategy&apos;: masked_array(data=[&apos;mean&apos;, &apos;mean&apos;, &apos;median&apos;, &apos;median&apos;],\n              mask=[False, False, False, False],\n        fill_value=&apos;?&apos;,\n             dtype=object),\n &apos;split1_train_score&apos;: array([0.66154782, 0.52599132, 0.6607045 , 0.52513119]),\n &apos;mean_fit_time&apos;: array([0.01534621, 0.0043029 , 0.00467904, 0.00462612]),\n &apos;split2_train_score&apos;: array([0.87701746, 0.85057325, 0.8772273 , 0.85099938]),\n &apos;param_lrg__fit_intercept&apos;: masked_array(data=[True, False, True, False],\n              mask=[False, False, False, False],\n        fill_value=&apos;?&apos;,\n             dtype=object),\n &apos;split0_test_score&apos;: array([0.58625867, 0.65741239, 0.59301577, 0.66211032]),\n &apos;std_fit_time&apos;: array([1.56081045e-02, 2.67946091e-04, 6.24979137e-05, 6.73512676e-05]),\n &apos;std_score_time&apos;: array([1.33632047e-03, 5.61170687e-06, 1.16280500e-05, 1.34099707e-05]),\n &apos;split2_test_score&apos;: array([ -5.73891503, -12.34910108,  -5.8632788 , -12.50591   ]),\n &apos;mean_test_score&apos;: array([-1.538804  , -3.75094573, -1.57726978, -3.80011965]),\n &apos;mean_score_time&apos;: array([0.00237028, 0.00142002, 0.0014379 , 0.00142376])}\n</div>"]}}],"execution_count":44},{"cell_type":"markdown","source":["There is a lot to notice here:\n- The keys that start with `param_` contain values from hyper-parameter options in `parameters`\n- The keys the end with `_test_score` contain results from the scoring of cross validation train-test pairs\n\nBelow this dictionary is converted into a dataframe. The key values are columns in the dataframe."],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\npd.DataFrame(data=est_grid_obj.cv_results_)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">18</span><span class=\"ansired\">]: </span>\n   mean_fit_time  mean_score_time  ...  std_test_score  std_train_score\n0       0.015346         0.002370  ...        2.969997         0.088440\n1       0.004303         0.001420  ...        6.080469         0.133221\n2       0.004679         0.001438  ...        3.030748         0.088829\n3       0.004626         0.001424  ...        6.156571         0.133657\n\n[4 rows x 18 columns]\n</div>"]}}],"execution_count":46},{"cell_type":"markdown","source":["__Aside:__ what does it mean to summarized one variable in terms of another?"],"metadata":{}},{"cell_type":"markdown","source":["The scoring results can be summarized in terms of the parameter options.\nThere are three reasons for this:\n1. The results are a __dataframe__\n2. The parameter options are __categorical variables__ (to be used by the `groupby` method)\n3. The score results are __numeric variables__ (to be used by the `agg` method)\n\nThe first and last items above are always true, but the second will require some work. We need to ensure that the values of the parameter options are either strings or integers (so they can be used by the `groupby` method).\n\nThe example below is a demonstration where this is not the case."],"metadata":{}},{"cell_type":"markdown","source":["I expect to use this often and so have placed the code above in a function (below)."],"metadata":{}},{"cell_type":"code","source":["def est_grid_results_pdf(my_est_grid_obj): \n  import pandas as pd\n  return pd.DataFrame(data=my_est_grid_obj.cv_results_)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":50},{"cell_type":"markdown","source":["__Exercise:__ Create a copy of `est_grid_results_pdf` and modify it to only return the parameter options and score results. Run it to produce a pandas dataframe with the reduced set of variable. \n\nSee `Cmd 24` (starting \"There is a lot to notice here\") for the variables."],"metadata":{}},{"cell_type":"markdown","source":["Three functions defined above are used below:\n- `bos_tgt_ser`: returns the target series from the Boston dataset using the `sklearn.datasets.load_boston` function \n- `bos_fea_pdf`: returns the feature dataframe from the Boston dataset using the `sklearn.datasets.load_boston` function \n- `est_grid_results_pdf`: returns the dataframe of results from a fitted `GridSearchCV` object"],"metadata":{}},{"cell_type":"markdown","source":["The exercises below will focus on the three code cells immediately below."],"metadata":{}},{"cell_type":"code","source":["from sklearn.pipeline        import Pipeline\nfrom sklearn.linear_model    import LogisticRegression, LinearRegression\nfrom sklearn.preprocessing   import MinMaxScaler\nfrom sklearn.impute          import SimpleImputer\n\nest_pipe = Pipeline([\n  ('imp', SimpleImputer()),\n  ('sca', MinMaxScaler()),\n  ('lrg', LinearRegression())\n])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":54},{"cell_type":"code","source":["parameters = {\n  'imp__strategy': ['mean', 'median'],\n  'lrg__fit_intercept': [True, False]\n}\n\nfrom sklearn.model_selection import GridSearchCV\n\nest_grid_obj = GridSearchCV(estimator=est_pipe, \n                        param_grid=parameters,\n                        cv=3, \n                        iid=False,\n                        return_train_score=False\n                       )\nest_grid_obj.fit(bos_fea_pdf(), \n                 bos_tgt_ser())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">21</span><span class=\"ansired\">]: </span>\nGridSearchCV(cv=3, error_score=&apos;raise-deprecating&apos;,\n       estimator=Pipeline(memory=None,\n     steps=[(&apos;imp&apos;, SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy=&apos;mean&apos;,\n       verbose=0)), (&apos;sca&apos;, MinMaxScaler(copy=True, feature_range=(0, 1))), (&apos;lrg&apos;, LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False))]),\n       fit_params=None, iid=False, n_jobs=None,\n       param_grid={&apos;lrg__fit_intercept&apos;: [True, False], &apos;imp__strategy&apos;: [&apos;mean&apos;, &apos;median&apos;]},\n       pre_dispatch=&apos;2*n_jobs&apos;, refit=True, return_train_score=False,\n       scoring=None, verbose=0)\n</div>"]}}],"execution_count":55},{"cell_type":"code","source":["est_grid_results_pdf(est_grid_obj)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">22</span><span class=\"ansired\">]: </span>\n   mean_fit_time  mean_score_time  ...  std_score_time std_test_score\n0       0.007460         0.001446  ...        0.000029       2.949638\n1       0.004180         0.001449  ...        0.000026       6.295999\n2       0.004680         0.001438  ...        0.000014       2.917676\n3       0.004664         0.001453  ...        0.000033       6.303666\n\n[4 rows x 13 columns]\n</div>"]}}],"execution_count":56},{"cell_type":"markdown","source":["__Exercise:__ Summarize the output from `est_grid_results_pdf(est_grid_obj)` with the `groupby` and `agg` methods.\n\nI understand that there are only four cases and that you can do this visually, but use these methods to learn the technique."],"metadata":{}},{"cell_type":"markdown","source":["The following two lines of code show how to use the groupby and agg functions.  There is not much of interest going on with the code or much worth noting here."],"metadata":{}},{"cell_type":"code","source":["x = est_grid_results_pdf(est_grid_obj).groupby(est_grid_results_pdf(est_grid_obj)['mean_fit_time'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":59},{"cell_type":"code","source":["x1 = est_grid_results_pdf(est_grid_obj).groupby(est_grid_results_pdf(est_grid_obj)['std_score_time'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":60},{"cell_type":"markdown","source":["__Exercise:__ copy the three code cells above and modify as below:\n- Add `SelectKBest()` to the pipeline in the third position, just before the `LinearRegression` \n- Run `GridSearchCV` on this pipeline (with the same parameters as before)\n- Check that reasonable looking results are produced by the `est_grid_results_pdf` function"],"metadata":{}},{"cell_type":"markdown","source":["This initial block of text serves to explain oour understanidng of the grid search method and works through the three code block segemnts. The first code block sets up the. creation of an estimator pipeline which includes the imported things from sklearn. The pipeline will unfctiono as an estimator, thus the need for us to put the SelectKBest above ogisitc regression, because had we not than there would have been issues in running. any predictions.  The next code block defines the parameters to be included in the grid search and under which the grid search will be conducted. For our purposes, the inital parameters are the imputing strtaegy being mean or median, and the logistiic regression intercept being true or false (indicating weather the log regression funciton needs to enter the origin).  After this, we load in the. Grid Search function, and create a grid search object, which takes the arguments estimator, parameter grid, and number of cross validations to be performed.  We also choose to specify iid to be false, and in our case return of the train score is set to false.  We finally call the object created to be fit onto the boston features dataframe and the boston target series - mimiking what will be expected out of us later on in the project.  We then call the pdf funtion defined above to show the results of the object we created (est_grid_object). Future text will refer nack to this cell as \"original explanation\"."],"metadata":{}},{"cell_type":"code","source":["from sklearn.pipeline        import Pipeline\nfrom sklearn.linear_model    import LogisticRegression, LinearRegression\nfrom sklearn.preprocessing   import MinMaxScaler\nfrom sklearn.impute          import SimpleImputer\nfrom sklearn.feature_selection import SelectKBest\n\nest_pipe = Pipeline([\n  ('imp', SimpleImputer()),\n  ('sca', MinMaxScaler()),\n  ('kbest', SelectKBest()),\n  ('lrg', LinearRegression())\n])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":63},{"cell_type":"code","source":["parameters = {\n  'imp__strategy': ['mean', 'median'],\n  'lrg__fit_intercept': [True, False]\n}\n\nfrom sklearn.model_selection import GridSearchCV\n\nest_grid_obj = GridSearchCV(estimator=est_pipe, \n                        param_grid=parameters,\n                        cv=3, \n                        iid=False,\n                        return_train_score=False\n                       )\nest_grid_obj.fit(bos_fea_pdf(), \n                 bos_tgt_ser())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">26</span><span class=\"ansired\">]: </span>\nGridSearchCV(cv=3, error_score=&apos;raise-deprecating&apos;,\n       estimator=Pipeline(memory=None,\n     steps=[(&apos;imp&apos;, SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy=&apos;mean&apos;,\n       verbose=0)), (&apos;sca&apos;, MinMaxScaler(copy=True, feature_range=(0, 1))), (&apos;kbest&apos;, SelectKBest(k=10, score_func=&lt;function f_classif at 0x7f1f8aac3f28&gt;)), (&apos;lrg&apos;, LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False))]),\n       fit_params=None, iid=False, n_jobs=None,\n       param_grid={&apos;lrg__fit_intercept&apos;: [True, False], &apos;imp__strategy&apos;: [&apos;mean&apos;, &apos;median&apos;]},\n       pre_dispatch=&apos;2*n_jobs&apos;, refit=True, return_train_score=False,\n       scoring=None, verbose=0)\n</div>"]}}],"execution_count":64},{"cell_type":"code","source":["est_grid_results_pdf(est_grid_obj)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">27</span><span class=\"ansired\">]: </span>\n   mean_fit_time  mean_score_time  ...  std_score_time std_test_score\n0       0.029098         0.003007  ...        0.000025       0.700250\n1       0.030743         0.002571  ...        0.000640       2.016271\n2       0.016862         0.001699  ...        0.000010       0.734699\n3       0.018962         0.001951  ...        0.000034       2.071746\n\n[4 rows x 13 columns]\n</div>"]}}],"execution_count":65},{"cell_type":"markdown","source":["__Exercise:__ copy the three code cells from the previous exercise and modify as below:\n- Add a key-value pair to the `parameters` dictionary for the `k` parameter of the `SelectKBest` class/object with value `[13,10,7,4]`\n- Run `GridSearchCV` on the pipeline with the new `parameters` dictionary\n- Use the `est_grid_results_pdf` function modified in a previous exercise\n- Check that reasonable looking results are produced and notice the column for the new parameter"],"metadata":{}},{"cell_type":"markdown","source":["This text block will discuss the additional code from the \"original explanation\".  The second line of code now includes a new parameter to be tested, the SelectKBest with differing values as specified in the exercise.  This means that the total number of results in or Grid Serach will be 16 (4x2x2) and mean sthat we will hopefully find a better answer when compared to previously run segments."],"metadata":{}},{"cell_type":"code","source":["from sklearn.pipeline        import Pipeline\nfrom sklearn.linear_model    import LogisticRegression, LinearRegression\nfrom sklearn.preprocessing   import MinMaxScaler\nfrom sklearn.impute          import SimpleImputer\nfrom sklearn.feature_selection import SelectKBest\n\nest_pipe = Pipeline([\n  ('imp', SimpleImputer()),\n  ('sca', MinMaxScaler()),\n  ('kbest', SelectKBest()),\n  ('lrg', LinearRegression())\n])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":68},{"cell_type":"markdown","source":["Note the presence of the kbest param."],"metadata":{}},{"cell_type":"code","source":["parameters = {\n  'imp__strategy': ['mean', 'median'],\n  'lrg__fit_intercept': [True, False],\n  'kbest__k': [13,10,7,4]\n}\n\nfrom sklearn.model_selection import GridSearchCV\n\nest_grid_obj = GridSearchCV(estimator=est_pipe, \n                        param_grid=parameters,\n                        cv=3, \n                        iid=False,\n                        return_train_score=False\n                       )\nest_grid_obj.fit(bos_fea_pdf(), \n                 bos_tgt_ser())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">29</span><span class=\"ansired\">]: </span>\nGridSearchCV(cv=3, error_score=&apos;raise-deprecating&apos;,\n       estimator=Pipeline(memory=None,\n     steps=[(&apos;imp&apos;, SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy=&apos;mean&apos;,\n       verbose=0)), (&apos;sca&apos;, MinMaxScaler(copy=True, feature_range=(0, 1))), (&apos;kbest&apos;, SelectKBest(k=10, score_func=&lt;function f_classif at 0x7f1f8aac3f28&gt;)), (&apos;lrg&apos;, LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False))]),\n       fit_params=None, iid=False, n_jobs=None,\n       param_grid={&apos;lrg__fit_intercept&apos;: [True, False], &apos;imp__strategy&apos;: [&apos;mean&apos;, &apos;median&apos;], &apos;kbest__k&apos;: [13, 10, 7, 4]},\n       pre_dispatch=&apos;2*n_jobs&apos;, refit=True, return_train_score=False,\n       scoring=None, verbose=0)\n</div>"]}}],"execution_count":70},{"cell_type":"code","source":["est_grid_obj.best_params_"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">30</span><span class=\"ansired\">]: </span>{&apos;lrg__fit_intercept&apos;: True, &apos;imp__strategy&apos;: &apos;median&apos;, &apos;kbest__k&apos;: 7}\n</div>"]}}],"execution_count":71},{"cell_type":"markdown","source":["Note there are 16 rows representing the 16 different grid boxes that were ran for the parameters given."],"metadata":{}},{"cell_type":"code","source":["est_grid_results_pdf(est_grid_obj)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">31</span><span class=\"ansired\">]: </span>\n    mean_fit_time  mean_score_time  ...  std_score_time std_test_score\n0        0.023445         0.002147  ...    6.229977e-04       2.910763\n1        0.016606         0.001700  ...    1.805416e-05       5.437493\n2        0.016789         0.001682  ...    1.197063e-05       0.880686\n3        0.016380         0.001692  ...    1.913399e-05       2.637301\n4        0.016813         0.001684  ...    2.103975e-05       0.316890\n5        0.016511         0.001711  ...    8.485379e-07       1.052552\n6        0.016758         0.001699  ...    1.214037e-05       1.139704\n7        0.016696         0.001704  ...    1.767516e-05       1.151538\n8        0.016984         0.001709  ...    5.106093e-06       2.825010\n9        0.016827         0.001768  ...    3.693171e-05       5.212288\n10       0.017157         0.001685  ...    2.192097e-05       0.822292\n11       0.016978         0.001676  ...    5.437942e-06       2.473927\n12       0.017026         0.001713  ...    3.327873e-05       0.309983\n13       0.016829         0.001709  ...    1.349963e-05       1.047450\n14       0.016680         0.001727  ...    5.866077e-05       1.077180\n15       0.017115         0.001719  ...    3.066025e-05       1.124270\n\n[16 rows x 14 columns]\n</div>"]}}],"execution_count":73},{"cell_type":"markdown","source":["__Exercise:__ copy the three code cells from the previous exercise and modify as below:\n- Import `f_regression` and `mutual_info_regression` from `sklearn.feature_selection` (first line of first code cell)\n- Add the `score_func` parameter of `SelectKBest` to the `parameters` dictionary with value `[f_regression,mutual_info_regression]`\n- Run `GridSearchCV` with this modified `parameters` dictionary\n- Check the column for the `score_func` parameter in the resulting dataframe. Notice that it is not a string or number."],"metadata":{}},{"cell_type":"markdown","source":["This text block will discuss the additional code from the \"original explanation\".  We add a new parameter to be considered from the kbest section.  This parameter specifies two different methodologies for the code to choose between, either f_regression or mutual_info_regression.  Note that the grid search was able to run before this because kbest had a default parameter for scoring originally.  Because of the increased parameters there will now be 32 grids or rows to consider when looking at our grid search results."],"metadata":{}},{"cell_type":"code","source":["from sklearn.pipeline        import Pipeline\nfrom sklearn.linear_model    import LogisticRegression, LinearRegression\nfrom sklearn.preprocessing   import MinMaxScaler\nfrom sklearn.impute          import SimpleImputer\nfrom sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n\nest_pipe = Pipeline([\n  ('imp', SimpleImputer()),\n  ('sca', MinMaxScaler()),\n  ('kbest', SelectKBest()),\n  ('lrg', LinearRegression())\n])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":76},{"cell_type":"markdown","source":["Note presence of the score function defined to test f_regression and mutual_info_regression"],"metadata":{}},{"cell_type":"code","source":["parameters = {\n  'imp__strategy': ['mean', 'median'],\n  'lrg__fit_intercept': [True, False],\n  'kbest__k': [13,10,7,4],\n  'kbest__score_func': [f_regression, mutual_info_regression]\n}\n\nfrom sklearn.model_selection import GridSearchCV\n\nest_grid_obj = GridSearchCV(estimator=est_pipe, \n                        param_grid=parameters,\n                        cv=3, \n                        iid=False,\n                        return_train_score=False\n                       )\nest_grid_obj.fit(bos_fea_pdf(), \n                 bos_tgt_ser())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">33</span><span class=\"ansired\">]: </span>\nGridSearchCV(cv=3, error_score=&apos;raise-deprecating&apos;,\n       estimator=Pipeline(memory=None,\n     steps=[(&apos;imp&apos;, SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy=&apos;mean&apos;,\n       verbose=0)), (&apos;sca&apos;, MinMaxScaler(copy=True, feature_range=(0, 1))), (&apos;kbest&apos;, SelectKBest(k=10, score_func=&lt;function f_classif at 0x7f1f8aac3f28&gt;)), (&apos;lrg&apos;, LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False))]),\n       fit_params=None, iid=False, n_jobs=None,\n       param_grid={&apos;kbest__score_func&apos;: [&lt;function f_regression at 0x7f1f8aad5158&gt;, &lt;function mutual_info_regression at 0x7f1f8a5e1ea0&gt;], &apos;lrg__fit_intercept&apos;: [True, False], &apos;imp__strategy&apos;: [&apos;mean&apos;, &apos;median&apos;], &apos;kbest__k&apos;: [13, 10, 7, 4]},\n       pre_dispatch=&apos;2*n_jobs&apos;, refit=True, return_train_score=False,\n       scoring=None, verbose=0)\n</div>"]}}],"execution_count":78},{"cell_type":"code","source":["est_grid_obj.best_params_"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">34</span><span class=\"ansired\">]: </span>\n{&apos;kbest__score_func&apos;: &lt;function sklearn.feature_selection.univariate_selection.f_regression&gt;,\n &apos;lrg__fit_intercept&apos;: True,\n &apos;imp__strategy&apos;: &apos;median&apos;,\n &apos;kbest__k&apos;: 4}\n</div>"]}}],"execution_count":79},{"cell_type":"markdown","source":["We note 32 potential rows to choose from when looking at the results."],"metadata":{}},{"cell_type":"code","source":["est_grid_results_pdf(est_grid_obj)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">35</span><span class=\"ansired\">]: </span>\n    mean_fit_time  mean_score_time  ...  std_score_time std_test_score\n0        0.005070         0.001553  ...    2.019424e-05       2.111515\n1        0.004952         0.001554  ...    2.148885e-05       5.221483\n2        0.066660         0.001680  ...    4.836758e-06       2.111515\n3        0.062445         0.001670  ...    1.795700e-05       5.221483\n4        0.004940         0.001546  ...    7.840875e-06       1.401716\n5        0.004896         0.001568  ...    2.245020e-06       3.980021\n6        0.069254         0.001712  ...    3.414208e-05       1.022314\n7        0.063256         0.001712  ...    8.693474e-06       0.762212\n8        0.004913         0.001556  ...    1.454462e-05       0.427734\n9        0.004825         0.001561  ...    1.693648e-05       0.917861\n10       0.065489         0.001703  ...    8.305579e-06       0.374454\n11       0.062385         0.001686  ...    2.725351e-06       1.078838\n12       0.004917         0.001545  ...    1.250480e-05       0.389971\n13       0.004997         0.001579  ...    1.480799e-05       0.974968\n14       0.064369         0.001818  ...    1.456221e-04       0.398291\n15       0.062607         0.001704  ...    1.749234e-05       1.751331\n16       0.005413         0.001676  ...    1.195295e-04       2.091197\n17       0.005336         0.001590  ...    6.257699e-07       5.323450\n18       0.063344         0.001694  ...    2.238625e-05       2.091197\n19       0.063517         0.001693  ...    1.461220e-05       5.323450\n20       0.005391         0.001591  ...    4.483002e-06       1.418517\n21       0.005296         0.001542  ...    6.432885e-06       4.089392\n22       0.063251         0.001699  ...    1.854598e-05       1.015126\n23       0.064278         0.001697  ...    1.650550e-05       0.806227\n24       0.005351         0.001596  ...    7.377719e-06       0.426264\n25       0.005377         0.001662  ...    8.536939e-05       0.919545\n26       0.063400         0.001689  ...    2.146915e-05       0.373777\n27       0.069586         0.001829  ...    1.905243e-04       1.081083\n28       0.005393         0.001577  ...    3.570092e-06       0.389015\n29       0.005258         0.001550  ...    3.316980e-06       0.975520\n30       0.062913         0.001778  ...    1.357780e-04       0.389387\n31       0.068377         0.002100  ...    4.643371e-04       1.752887\n\n[32 rows x 15 columns]\n</div>"]}}],"execution_count":81},{"cell_type":"markdown","source":["__Exercise:__ create a wrapper class called `SelectKBestWrap` for `SelectKBest`:\n- Create a `SelectKBest` object in the `init` method\n- Create an init parameter called `score_func_str` \n- When this parameter is `'f_regression'` then pass `f_regression` to `SelectKBest`\n- When this parameter is `'mutual_info_regression'` then pass `mutual_info_regression` to `SelectKBest`\n- You will need to create `fit` and `transform` methods (see examples from a previous week) which return results \n- Test this function on the Boston features dataframe and the target series"],"metadata":{}},{"cell_type":"markdown","source":["The below code creates teh wrapper class for the SelectKBEst functionality.  We coded into the int function two if tests to dtermine what the input was for the given results.  When writting this code it is important to specify this, because it will allow us to perform the analyses needed without typing them in or knowing them - this could proove useful in machine learning, because we will now be able to take the output from our grid search, and refer to i as the input needed for the wrapper class and conduct further analyses."],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":84},{"cell_type":"code","source":["from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass SelectKBestWrap(BaseEstimator, TransformerMixin):\n  def __init__ (self, score_func_str):\n    self.score_func_str = score_func_str\n    if self.score_func_str == 'f_regression':\n      abc = f_regression\n    if self.score_func_str == 'mutual_info_regression':\n      abc = mutual_info_regression\n    self.SK=SelectKBest(score_func = abc,k=6)\n  def fit(self,X,y):\n    self.SK.fit(X,y)\n    return self\n  def transform(self, X):\n    X=self.SK.transform(X)\n    return X"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":85},{"cell_type":"markdown","source":["We see below the code functioning as expected, by replacing the 'na' portions of the features df with the mean (simple form of imputing) we are then able to use our transformer pipeline defined above. We note that the below output is working because there are a similar amount of rows to the original dataset, and the number of columns fitrs with what was specified in the SelectKBest wrapper class."],"metadata":{}},{"cell_type":"code","source":["raw1=bos_fea_pdf()\nraw2=raw1.fillna(raw1.iloc[0,:].mean())\na=SelectKBestWrap('f_regression').fit_transform(raw2, bos_tgt_ser())\na.shape"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">37</span><span class=\"ansired\">]: </span>(506, 6)\n</div>"]}}],"execution_count":87},{"cell_type":"markdown","source":["## 3. Datasets"],"metadata":{}},{"cell_type":"markdown","source":["This section contains the location and a few notes about the datasets from a previous week."],"metadata":{}},{"cell_type":"markdown","source":["Display the paths of the three files in our dataset."],"metadata":{}},{"cell_type":"code","source":["%sh ls -hot /dbfs/mnt/group-ma707/data/*"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">-rw-r--r-- 1 root 259K Jan 29 17:44 /dbfs/mnt/group-ma707/data/5tc_plus_ind_vars.csv\n-rw-r--r-- 1 root  12M Jan 29 17:44 /dbfs/mnt/group-ma707/data/mining_com_coal.csv\n-rw-r--r-- 1 root  11M Jan 29 17:44 /dbfs/mnt/group-ma707/data/mining_com_iron_ore.csv\n</div>"]}}],"execution_count":91},{"cell_type":"markdown","source":["__Note:__ we will create, from the above files, at least three dataframes (with features and target). Each is described below.\n\nFrom only the 5TC dataset: \n- target will be `BCI`\n- features will include lagged versions of the other columns \n- features will include date and time components (hour, day of week, etc.)\n- features may include external time series\n\nFrom only the _mining_ dataset(s):\n- the target may be one or more tags (from the `tags` variable)\n- features would be words present in the `content` or `title` variables\n\nFrom the 5TC and _mining_ dataset(s): \n- target will be `BCI` (from 5TC dataframe)\n- include all features from either of the above dataframes\n- the dataframes would need to be joined by either:\n    1. aggregating the features from the _mining_ dataframe (by date)\n    1. spreading the 5TC dataframe onto the _mining_ dataframe (duplicating 5TC rows)"],"metadata":{}},{"cell_type":"markdown","source":["__The End__"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":94}],"metadata":{"name":"W06.1 Ex. Grid Search","notebookId":1130243},"nbformat":4,"nbformat_minor":0}
