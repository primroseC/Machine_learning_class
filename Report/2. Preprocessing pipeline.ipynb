{"cells":[{"cell_type":"markdown","source":["This notebook contains code to create feature-target datasets. \nThis code will include the `FeatureUnionDF` class, the `DropNaRowsDF` class and the feature creation classes. \nThe code will be reused in the `Investigation` notebook."],"metadata":{}},{"cell_type":"markdown","source":["#MA707 Report - Preprocessing (spring 2019, Blackjack)"],"metadata":{}},{"cell_type":"markdown","source":["## Introduction"],"metadata":{}},{"cell_type":"markdown","source":["## Contents\n1. Setup"],"metadata":{}},{"cell_type":"markdown","source":["## 1. Setup"],"metadata":{}},{"cell_type":"code","source":["%run \"./1. Class demonstrations\""],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["Rather than transport code already written, we utilize the run method introduced to us before - which is incredibly useful."],"metadata":{}},{"cell_type":"markdown","source":["Below, we create a preprocessing pipeline that takes FeatureUnioin and Pipeline as arguments and creates two distinct feature unions.  The first feature union combines the target variables, date and time variables, and lagged variables of the numeric data and the text data into the first feature union. We drop the rows created with NA, so we do not create a problem later on when running our data through any future pipelines and attempting to predict.  Second, the feature union is called again, this time creating a union between the countvecorized variables for the lagged tags and title variables created above.  Note we choose to ignore content because of the sheer computing power it would take to run the model, and our opinion that content will not be useful in predicting."],"metadata":{}},{"cell_type":"code","source":["%python \ndef get_count_plus_ts_lag1_pipe():\n  from sklearn.pipeline import FeatureUnion, Pipeline\n  return Pipeline(steps=[\n    ('fea_one', FeatureUnionDF(transformer_list=[\n      ('tgt_var'    ,CreateTargetVarDF(var='bci_5tc')),\n      ('dt_vars'    ,CreateDatetimeVarsDF(var='date')),\n      ('lag_ts_vars',CreateLagVarsDF(\n        var_list=['cme_ln2','rici','p1a_03','p4_03','c7',\n                  'cme_ln3','p3a_03','shfe_rb3','shfe_al3',\n                  'shfe_cu3','ice_tib3','cme_fc3','opec_orb',\n                  'ice_sb3','p3a_iv','ice_kc3','c5',\n                  'p2a_03','cme_lc2','cme_sm3','ice_tib4','bci','cme_ln1','cme_s2'],\n        lag_list=[1])),\n      ('lag_txt_vars',CreateLagVarsDF(var_list=['tags','title'],\n                                      lag_list=[1])),\n    ])),\n    ('drop_na_rows'  ,DropNaRowsDF(how='any')),\n    ('fea_two', FeatureUnionDF(transformer_list=[\n      ('named_vars' ,CreateNamedVarsDF(except_list=['tags_lag1','title_lag1'])),\n      ('cnt_tags'   , CountVectColDF(col_name=   'tags_lag1',prefix='cnt_tags_'   ,add_stop_words=[])),\n     # ('cnt_content', CountVectColDF(col_name='content_lag1',prefix='cnt_content_',add_stop_words=[])),  \n      ('cnt_title'  , CountVectColDF(col_name=  'title_lag1',prefix='cnt_title_'  ,add_stop_words=[])),  \n    ])),\n    ('drop_na_rows_again'  ,DropNaRowsDF(how='any')),\n  ])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["Rather than restate what has been done - note that the below simply changes the lag time period from 1 to 3"],"metadata":{}},{"cell_type":"code","source":["%python \ndef get_count_plus_ts_lag3_pipe():\n  from sklearn.pipeline import FeatureUnion, Pipeline\n  return Pipeline(steps=[\n    ('fea_one', FeatureUnionDF(transformer_list=[\n      ('tgt_var'    ,CreateTargetVarDF(var='bci_5tc')),\n      ('dt_vars'    ,CreateDatetimeVarsDF(var='date')),\n      ('lag_ts_vars',CreateLagVarsDF(\n        var_list=['cme_ln2','rici','p1a_03','p4_03','c7',\n                  'cme_ln3','p3a_03','shfe_rb3','shfe_al3',\n                  'shfe_cu3','ice_tib3','cme_fc3','opec_orb',\n                  'ice_sb3','p3a_iv','ice_kc3','c5',\n                  'p2a_03','cme_lc2','cme_sm3','ice_tib4','bci','cme_ln1','cme_s2'],\n        lag_list=[3])),\n      ('lag_txt_vars',CreateLagVarsDF(var_list=['tags','title'],\n                                      lag_list=[3])),\n    ])),\n    ('drop_na_rows'  ,DropNaRowsDF(how='any')),\n    ('fea_two', FeatureUnionDF(transformer_list=[\n      ('named_vars' ,CreateNamedVarsDF(except_list=['tags_lag3','title_lag3'])),\n      ('cnt_tags'   , CountVectColDF(col_name=   'tags_lag3',prefix='cnt_tags_'   ,add_stop_words=[])),\n      ('cnt_title'  , CountVectColDF(col_name=  'title_lag3',prefix='cnt_title_'  ,add_stop_words=[])),  \n     # ('cnt_content', CountVectColDF(col_name='content_lag3',prefix='cnt_content_',add_stop_words=[])),  \n    ])),\n    ('drop_na_rows_again'  ,DropNaRowsDF(how='any')),\n  ])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["Here we create our feature target data frames for the coal and ore raw datasets by calling the pipelines created above.  These data frames will be a combination of the lagged numeric data, and the countvectorizer results of the tags and title (as well as the actual words, which will be ignored in any sort of pipeline that takes place)"],"metadata":{}},{"cell_type":"code","source":["fea_tgt_coal_pdf_lag1 = get_count_plus_ts_lag1_pipe().fit(bci_coal_pdf).transform(bci_coal_pdf)\nfea_tgt_coal_pdf_lag3 =  get_count_plus_ts_lag3_pipe().fit(bci_coal_pdf).transform(bci_coal_pdf)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["fea_tgt_ore_pdf_lag1 = get_count_plus_ts_lag1_pipe().fit(bci_ore_pdf).transform(bci_ore_pdf)\nfea_tgt_ore_pdf_lag3 =  get_count_plus_ts_lag3_pipe().fit(bci_ore_pdf).transform(bci_ore_pdf)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["Below, we take the pipeline that had been applied above, and replace countvectorizer with tfidfvectorizer.  This will hypothetically provide an estimate that shows a tag or titles relevance in a given line"],"metadata":{}},{"cell_type":"code","source":["%python \ndef get_tfidf_plus_ts_lag1_pipe():\n  from sklearn.pipeline import FeatureUnion, Pipeline\n  return Pipeline(steps=[\n    ('fea_one', FeatureUnionDF(transformer_list=[\n      ('tgt_var'    ,CreateTargetVarDF(var='bci_5tc')),\n      ('dt_vars'    ,CreateDatetimeVarsDF(var='date')),\n      ('lag_ts_vars',CreateLagVarsDF(\n        var_list=['cme_ln2','rici','p1a_03','p4_03','c7',\n                  'cme_ln3','p3a_03','shfe_rb3','shfe_al3',\n                  'shfe_cu3','ice_tib3','cme_fc3','opec_orb',\n                  'ice_sb3','p3a_iv','ice_kc3','c5',\n                  'p2a_03','cme_lc2','cme_sm3','ice_tib4','bci','cme_ln1','cme_s2'],\n        lag_list=[1])),\n      ('lag_txt_vars',CreateLagVarsDF(var_list=['tags','title'],\n                                      lag_list=[1])),\n    ])),\n    ('drop_na_rows'  ,DropNaRowsDF(how='any')),\n    ('fea_two', FeatureUnionDF(transformer_list=[\n      ('named_vars' ,CreateNamedVarsDF(except_list=['tags_lag1','title_lag1'])),\n      ('tfidf_tags'   , TfidfVectColDF(col_name=   'tags_lag1',prefix='tfidf_tags_'   ,add_stop_words=[])),\n      ('tfidf_title'  , TfidfVectColDF(col_name=  'title_lag1',prefix='tfidf_title_'  ,add_stop_words=[])),  \n     # ('cnt_content', CountVectColDF(col_name='content_lag3',prefix='cnt_content_',add_stop_words=[])),  \n    ])),\n    ('drop_na_rows_again'  ,DropNaRowsDF(how='any')),\n  ])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["Below, our feature-target dataframes are created for tfidf."],"metadata":{}},{"cell_type":"code","source":["fea_tgt_coal_pdf_tfidf_lag1 = get_tfidf_plus_ts_lag1_pipe().fit(bci_coal_pdf).transform(bci_coal_pdf)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["fea_tgt_ore_pdf_tfidf_lag1 = get_tfidf_plus_ts_lag1_pipe().fit(bci_ore_pdf).transform(bci_ore_pdf)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["## Summary"],"metadata":{}},{"cell_type":"markdown","source":["In this notebook, we sought to create target-feature data frames that could then be used in our estimator pipelines.  We utilized classes previously discussed such as the dropNArows, and the wrapper class of FeatureUnion to accomplish this, as well as considered the different ways of processing words by using both countvectorizer and tfidf vectorizer separately in different pipelines.  Moving forward, we will create train/test separated datasets and will explore different estimator pipelines per our stated objectives and goals"],"metadata":{}}],"metadata":{"name":"2. Preprocessing pipeline","notebookId":1453896},"nbformat":4,"nbformat_minor":0}
