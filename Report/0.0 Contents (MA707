{"cells":[{"cell_type":"markdown","source":["#MA707 Report - Introduction (spring 2019, BlackJack)"],"metadata":{}},{"cell_type":"markdown","source":["## Introduction"],"metadata":{}},{"cell_type":"markdown","source":["## Links to report sections (other notebooks)\n1. [Demonstrate classes](https://bentley.cloud.databricks.com/#notebook/1454140/command/1454141): demonstrate individual wrapper classes\n1. [Preprocessing pipelines](https://bentley.cloud.databricks.com/#notebook/1453896/command/1453897): demonstrate preprocessing pipelines\n2. [Estimator pipelines](https://bentley.cloud.databricks.com/#notebook/1454013/command/1454014): demonstrate estimator pipelines\n3. [Investigations](https://bentley.cloud.databricks.com/#notebook/1453740/command/1453741): use `GridSearchCV` with estimator pipelines and feature-target datasets (created with preprocessing pipelines) to learn which hyper-parameters and which features work well and which don't\n4. [Investigations - LSTM and Sequential](https://bentley.cloud.databricks.com/#notebook/1454461/command/1454462): Our attempt at LSTM analysis\n\nInclude notebooks\n1. [Raw dataset (inc)](https://bentley.cloud.databricks.com/#notebook/1453698/command/1453712)\n1. [Feature creation (inc)](https://bentley.cloud.databricks.com/#notebook/1453669/command/1453670)\n2. [Feature selection (inc)](https://bentley.cloud.databricks.com/#notebook/1454239/command/1454240)\n1. [Estimators (inc)](https://bentley.cloud.databricks.com/#notebook/1453892/command/1453893)\n1. [Pipeline functions (inc)](https://bentley.cloud.databricks.com/#notebook/1453894/command/1453895)"],"metadata":{}},{"cell_type":"markdown","source":["## Contents (this notebook)\n1. Dataset description\n1. Objectives\n1. Plan"],"metadata":{}},{"cell_type":"markdown","source":["## 1. Dataset description"],"metadata":{}},{"cell_type":"markdown","source":["The dataset in consideration is a combination of the bci_5 index, variables often consulted when determining movements in the bci_5 index, and tweets relating to coal and iron ore mining.  Our specific datasets considered will be twofold, one will be a merge between the bci data and the coal data, while the other will be a merge between the bci data and the iron ore data."],"metadata":{}},{"cell_type":"markdown","source":["## 2. Objectives"],"metadata":{}},{"cell_type":"markdown","source":["For our considerations into the project, we will be interested in looking at several things.  First, we are curious as to what type of regressor model, the RIDGE, LASSO, or Elastic Net will provide the most accurate predictions for the target variable(s). We are curious of this because of the models similarities as well as differences in handling highly correlated data, and believe that Elastic Net, taking a combination of the RIDGE and LASSO models will provide the best answer.  In order to prove this objective, we have a secondary goal of determining optimal levels for Principal Component Analysis (PCA) and Alpha level within the three models.  We believe that each model will need unique parameters in order to function correctly, and that while they have similar goals, each one will have a different response to different parametric tuning. From here, we wish to test the difference in lagging variables 1 day or 3 days.  We believe that 3 days lagged variables will be “too late” in terms of predicting the model as accurately as 1-day lags – however we also note that information flow may not be sufficiently fast to reflect correctly what happens in one day and therefore we are curious to see what happens.  We will also consider the difference in two dataset and their predictive ability, as well as the difference in using CountVecorizer and TFIDF Vectorizer."],"metadata":{}},{"cell_type":"markdown","source":["## 3. Plan"],"metadata":{}},{"cell_type":"markdown","source":["We will start by introducing code that will be needed throughout the project in order to create working train/test datasets and the initial preprocessing pipelines through which our information can flow.  From there we will create four preprocessing pipelines (one for each lag and vectorizer combo).  We will write code which creates train and test data, so as to avoid data leakage and will create a handful of estimator pipelines that consider the different types of regression, as well as scaled against unscaled variables.  After creating these, we will run a number of grid search objects in the hope of finding the best parameters for each model on a one lag variable dataset.  We will select the top three models (one each from RIDGE, LASSO, and Elastic Net) and then run a myriad of tests and results to answer our objective questions listed above."],"metadata":{}},{"cell_type":"markdown","source":["## Summary"],"metadata":{}},{"cell_type":"markdown","source":["In conclusion, our goal of the project was to observe the effects different regressors have on our target variable, the bci_5 index.  We created feature target data frame’s consisting of both numeric and textual data and built several estimator pipelines to test out our theories.  In the end, we concluded that the RIDGE regressor provided the most accurate results, and that factors such as lag were incredibly important in our prediction, but type of vectorizer did not provide much additional information.  We also provide a separate investigations notebook which explores the LSTM model, as well as a model developed only off of natural text processing."],"metadata":{}}],"metadata":{"name":"0.0 Contents (MA707, TBI)","notebookId":1453684},"nbformat":4,"nbformat_minor":0}
