{"cells":[{"cell_type":"markdown","source":["#MA707 Report - Class Demonstrations (spring 2019, Blackjack)"],"metadata":{}},{"cell_type":"markdown","source":["## Introduction"],"metadata":{}},{"cell_type":"markdown","source":["## Contents\n1. Setup"],"metadata":{}},{"cell_type":"markdown","source":["## 1. Setup"],"metadata":{}},{"cell_type":"code","source":["%run \"./0.1 Raw dataset (inc)\""],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["%run \"./0.2 Feature creation (inc)\""],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["%run \"./0.3 Feature selection (inc)\""],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["%run \"./0.4 Estimators (inc)\""],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## 2. Class demonstrations"],"metadata":{}},{"cell_type":"markdown","source":["The following subsections demonstrate the classes used by the `FeatureUnion` and `Pipeline` classes to create a feature-target dataframe."],"metadata":{}},{"cell_type":"markdown","source":["### 2.1 `CreateTargetDF`"],"metadata":{}},{"cell_type":"markdown","source":["The below code creates a target data frame from the bci_coal data frame, where the target variable is the bci_5 index.  The below method will be useful in creating our preprocessing pipeline, but we should be careful when moving forward to only include predictor variables we want to consider."],"metadata":{}},{"cell_type":"code","source":["%python\nCreateTargetVarDF(var='bci_5tc') \\\n  .fit_transform(bci_coal_pdf) \\\n  .head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">41</span><span class=\"ansired\">]: </span>\n   target\n0   29966\n1   29990\n2   30337\n3   31803\n4   33276\n</div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["### 2.2 `CreateDatetimeVarsDF`"],"metadata":{}},{"cell_type":"markdown","source":["The below code takes as argument the variable date, and then splits the datetime variable already contained in our dataset into the independent values below. Something like this may prove useful if we choose to explore how day of week or day in year could impact the target variable, and potentially observe price fluctuations that align with seasonality or other macroeconomic factors we may not be able to see elsewhere."],"metadata":{}},{"cell_type":"code","source":["%python\nCreateDatetimeVarsDF(var='date',\n                     var_list=['year','month','day',\n                               'dayofyear','weekofyear','weekday']) \\\n  .fit_transform(bci_coal_pdf) \\\n  .head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">42</span><span class=\"ansired\">]: </span>\n   year  month  day  dayofyear  weekofyear  weekday\n0  2011     12    5        339          49        0\n1  2011     12    6        340          49        1\n2  2011     12    7        341          49        2\n3  2011     12    8        342          49        3\n4  2011     12    9        343          49        4\n</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["### 2.3 `CreateLagVarsDF`"],"metadata":{}},{"cell_type":"markdown","source":["Lagged variables will be incredibly important for our purposes moving forward, because they represent the easiest way to formulate a prediction for our datasets.  When considering the lagged variables, one thing we will want to pay special attention to is the time period we consider for lagging everything - for example, a lagged variable of one day may provide a much different result than a lagged variable of 3 days, due to the relative speed with which information is transferred these days."],"metadata":{}},{"cell_type":"code","source":["%python\nCreateLagVarsDF(var_list=['cme_ln2','rici','p1a_03','p4_03','c7',\n                          'cme_ln3','p3a_03','shfe_rb3','shfe_al3',\n                          'shfe_cu3','ice_tib3','cme_fc3','opec_orb',\n                          'ice_sb3','p3a_iv','ice_kc3','c5',\n                          'p2a_03','cme_lc2','content','cme_sm3',\n                          'ice_tib4','bci','tags','cme_ln1','cme_s2'],\n                lag_list=range(0,2)) \\\n  .fit_transform(bci_coal_pdf) \\\n  .loc[:5,['bci_lag0','bci_lag1']] \\\n  .head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">43</span><span class=\"ansired\">]: </span>\n   bci_lag0  bci_lag1\n0      3390       NaN\n1      3387    3390.0\n2      3405    3387.0\n3      3529    3405.0\n4      3697    3529.0\n</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["The below indicates that the lagged data frame now exists, with bci_lag1 shifted back one full day behind its actual indexing"],"metadata":{}},{"cell_type":"code","source":["bci_coal_pdf \\\n  .loc[:,['date','bci']] \\\n  .head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">44</span><span class=\"ansired\">]: </span>\n        date   bci\n0 2011-12-05  3390\n1 2011-12-06  3387\n2 2011-12-07  3405\n3 2011-12-08  3529\n4 2011-12-09  3697\n</div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["### 2.3 `DropNaRowsDF`"],"metadata":{}},{"cell_type":"markdown","source":["As a result of creating lagged variables, we will lose some data at both the start and end of the dataset, because there will not be observations for those time periods. This will throw an exception due to NA's being present in the dataset. To combat this problem, we will use DropNARows from the dataset.  While this solves our NA problem, one must be careful on dataset size and amount of time lagged.  We are currently working with a large dataset so there is not much concern, but should we have a smaller dataset the information lost from dropping the rows may create problems."],"metadata":{}},{"cell_type":"code","source":["%python \nfrom sklearn.pipeline import Pipeline\nxfm_pipe = Pipeline(\n  steps=[('lag',CreateLagVarsDF(var_list=['cme_ln2','rici','p1a_03','p4_03','c7','cme_ln3','p3a_03','shfe_rb3','shfe_al3',\n                                          'shfe_cu3','ice_tib3','cme_fc3','opec_orb','ice_sb3','p3a_iv','ice_kc3','c5',\n                                          'p2a_03','cme_lc2','content','cme_sm3','ice_tib4','bci','tags','cme_ln1','cme_s2'],\n                                lag_list=range(0,3)))\n        ])\nxfm_pipe \\\n  .fit_transform(bci_pdf) \\\n  .loc[:,['bci_lag0',\n          'bci_lag1',\n          'bci_lag2']] \\\n  .head(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">45</span><span class=\"ansired\">]: </span>\n   bci_lag0  bci_lag1  bci_lag2\n0      3390       NaN       NaN\n1      3387    3390.0       NaN\n2      3405    3387.0    3390.0\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["Above, we see what happens when we allow the NaN rows to exist, and below - what happens when we allow the rows to be dropped, it should be noted that we have lost the first two daysâ€™ worth of information from utilizing this coded technique."],"metadata":{}},{"cell_type":"code","source":["%python \nfrom sklearn.pipeline import Pipeline\nxfm_pipe = Pipeline(\n  steps=[('lag',CreateLagVarsDF(var_list=['cme_ln2','rici','p1a_03','p4_03','c7','cme_ln3','p3a_03','shfe_rb3','shfe_al3',\n                                          'shfe_cu3','ice_tib3','cme_fc3','opec_orb','ice_sb3','p3a_iv','ice_kc3','c5',\n                                          'p2a_03','cme_lc2','content','cme_sm3','ice_tib4','bci','tags','cme_ln1','cme_s2'],\n                                lag_list=range(0,3))),\n         ('row',DropNaRowsDF(how='any'))\n        ])\nxfm_pipe \\\n  .fit_transform(bci_pdf) \\\n  .loc[:,['bci_lag0',\n          'bci_lag1',\n          'bci_lag2']] \\\n  .head(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">46</span><span class=\"ansired\">]: </span>\n   bci_lag0  bci_lag1  bci_lag2\n2      3405    3387.0    3390.0\n3      3529    3405.0    3387.0\n</div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["### 2.4 `CountVectColDF`"],"metadata":{}},{"cell_type":"markdown","source":["The below code begins to highlight how the countVect wrapped class can be defined and brought to work.  We will use this, along with other fitting techniques (Tfidf, PCA, etc.) to perform evaluations on our working model and in our preprocessing pipelines."],"metadata":{}},{"cell_type":"code","source":["%python \nfrom sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\nclass CountVectColDF(CountVectorizer):\n  def __init__(self,col_name,prefix='cnt_',\n               stop_words=list(ENGLISH_STOP_WORDS),\n               add_stop_words=[]\n              ):\n    stop_words_list = stop_words+add_stop_words\n    self.col_name = col_name\n    self.prefix   = prefix\n    super().__init__(stop_words=stop_words_list)\n    return\n  \n  def fit(self,X,y=None):\n    super().fit(X[self.col_name])\n    return self\n  \n  def transform(self,X,y=None):\n    return pd.DataFrame(data=super().transform(X[self.col_name]).toarray(),\n                        columns=[self.prefix+feature_name for feature_name in super().get_feature_names()]\n                       )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["Below, we implement the CountVect wrapped class to demonstrate how the code will function in our pre processing pipeline."],"metadata":{}},{"cell_type":"code","source":["%python\nCountVectColDF(col_name='tags',\n               prefix='cnt_',\n               add_stop_words=['2012']) \\\n  .fit(bci_coal_pdf) \\\n  .transform(bci_coal_pdf) \\\n  .head() \\\n  .columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">48</span><span class=\"ansired\">]: </span>\nIndex([&apos;cnt_acquisitions&apos;, &apos;cnt_adani&apos;, &apos;cnt_adaro&apos;, &apos;cnt_administration&apos;,\n       &apos;cnt_aes&apos;, &apos;cnt_afghanistan&apos;, &apos;cnt_africa&apos;, &apos;cnt_ag&apos;, &apos;cnt_agency&apos;,\n       &apos;cnt_agnico&apos;,\n       ...\n       &apos;cnt_xstrata&apos;, &apos;cnt_yancoal&apos;, &apos;cnt_yanzhou&apos;, &apos;cnt_yukon&apos;, &apos;cnt_zambia&apos;,\n       &apos;cnt_zealand&apos;, &apos;cnt_zijin&apos;, &apos;cnt_zimbabwe&apos;, &apos;cnt_zimplats&apos;, &apos;cnt_zinc&apos;],\n      dtype=&apos;object&apos;, length=606)\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["### 2.5 `TfidfVectColDF`"],"metadata":{}},{"cell_type":"markdown","source":["The below code is very similar to the above code, however the main difference is the presence of the Tfidf vectorizer as compared to countvectorizer.  This difference may prove to be relevant pending how we attempt to process with natural language and understand the relationship between words and word groups as opposed to single words."],"metadata":{}},{"cell_type":"code","source":["%python \nfrom sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\nclass TfidfVectColDF(TfidfVectorizer):\n  def __init__(self,col_name,prefix='cnt_',\n               stop_words=list(ENGLISH_STOP_WORDS),\n               add_stop_words=[]\n              ):\n    stop_words_list = stop_words+add_stop_words\n    self.col_name = col_name\n    self.prefix   = prefix\n    super().__init__(stop_words=stop_words_list)\n    return\n  \n  def fit(self,X,y=None):\n    super().fit(X[self.col_name])\n    return self\n  \n  def transform(self,X,y=None):\n    return pd.DataFrame(data=super().transform(X[self.col_name]).toarray(),\n                        columns=[self.prefix+feature_name for feature_name in super().get_feature_names()]\n                       )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"markdown","source":["## Summary"],"metadata":{}},{"cell_type":"markdown","source":["Above - we demonstrate some of the classes that will need to be used in our future notebooks.  Showing these classes here not only allows us to determine that they work but shows us what the output might happen to be - which will be important because knowing the output allows us to better determine which feature selection methods will work best for our investigation."],"metadata":{}}],"metadata":{"name":"1. Class demonstrations","notebookId":1454140},"nbformat":4,"nbformat_minor":0}
